<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Yüzük Deneme Uygulaması</title>

    <script type="importmap">
      {
        "imports": {
          "three": "https://unpkg.com/three@0.152.2/build/three.module.js",
          "three/examples/jsm/loaders/GLTFLoader": "https://unpkg.com/three@0.152.2/examples/jsm/loaders/GLTFLoader.js",
          "@tensorflow/tfjs": "https://unpkg.com/@tensorflow/tfjs@4.18.0/dist/tf.js",
          "@mediapipe/hands": "https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675468705",
          "@tensorflow-models/hand-pose-detection": "https://unpkg.com/@tensorflow-models/hand-pose-detection@2.1.1/dist/hand-pose-detection.js"
        }
      }
    </script>
    
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            text-align: center;
            background: #f0f0f0;
            overflow: hidden;
        }

        #video, #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 1;
        }

        canvas {
            z-index: 2;
        }

        #video {
            display: none;
        }

        #startButton {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 10;
            padding: 15px 30px;
            font-size: 20px;
            cursor: pointer;
            border: none;
            border-radius: 8px;
            background-color: #333;
            color: white;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
            transition: background-color 0.2s;
        }

        #startButton:hover {
            background-color: #555;
        }
    </style>
</head>
<body>
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas"></canvas>
    <button id="startButton">Yüzüğü Gör</button>
    
   <script type="module">
    import * as THREE from 'three';
    import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader';
    
    // Kütüphaneler importmap üzerinden modül olarak alınıyor
    import * as tf from '@tensorflow/tfjs';
    import * as handPoseDetection from '@tensorflow-models/hand-pose-detection';
    
    const MEDIAPIPE_SOLUTION_PATH = 'https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675468705';

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const startButton = document.getElementById('startButton');

    let scene, camera, renderer, ring;
    let videoWidth, videoHeight;
    let detector; 

    async function initThree() {
        renderer = new THREE.WebGLRenderer({ canvas, alpha: true, antialias: true });
        renderer.setClearColor(0x000000, 0);

        const aspectRatio = window.innerWidth / window.innerHeight;
        camera = new THREE.PerspectiveCamera(75, aspectRatio, 0.1, 1000);
        camera.position.z = 2;
        
        scene = new THREE.Scene();
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);
        const dirLight = new THREE.DirectionalLight(0xffffff, 1.5);
        dirLight.position.set(2, 5, 4);
        scene.add(dirLight);

        const loader = new GLTFLoader();
        loader.load('models/ring.glb', (gltf) => { 
            ring = gltf.scene;
            ring.scale.set(0.03, 0.03, 0.03); 
            ring.rotation.x = Math.PI / 2;
            scene.add(ring);
            console.log("Yüzük modeli yüklendi.");
        }, undefined, (error) => {
            console.error('Yüzük modeli yüklenirken bir hata oluştu: "models/ring.glb" dosya yolunu kontrol edin.', error);
        });

        window.addEventListener('resize', () => {
            const width = window.innerWidth;
            const height = window.innerHeight;
            renderer.setSize(width, height);
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
    }

    async function initHandDetector() {
        await tf.ready();
        console.log("TensorFlow çekirdeği tamamen hazır."); 

        await tf.setBackend('webgl'); 
        console.log("TensorFlow backend ayarlandı.");
        
        const detectorConfig = {
            runtime: 'mediapipe',
            solutionPath: MEDIAPIPE_SOLUTION_PATH, 
            modelType: 'lite',
            maxHands: 1
        };
        
        // Hata çözüldü: handPoseDetection modül adı üzerinden kullanılıyor.
        detector = await handPoseDetection.createDetector(handPoseDetection.SupportedModels.MediaPipeHands, detectorConfig);
        console.log("El dedektörü hazır.");
    }
    
    async function start() {
        startButton.disabled = true;
        startButton.textContent = 'Yükleniyor...';

        try {
            await Promise.all([initHandDetector(), initThree()]); 

            // Kamera izni burada istenir
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            
            video.onloadeddata = () => {
                videoWidth = video.videoWidth;
                videoHeight = video.videoHeight;
                
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();

                video.style.display = 'block';
                detectHands();
                startButton.style.display = 'none'; 
            };

            video.play();

        } catch (error) {
            console.error("Uygulama başlatılamadı:", error);
            startButton.textContent = 'Kamera Hatası veya Model Yüklenemedi';
            startButton.disabled = false;
        }
    }

    async function detectHands() {
        
        if (renderer.getSize(new THREE.Vector2()).width !== window.innerWidth) {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
        }

        const hands = await detector.estimateHands(video, { flipHorizontal: true });

        if (hands.length > 0 && ring) {
            const fingerKnuckle = hands[0].keypoints.find(k => k.name === 'index_finger_pip');

            if (fingerKnuckle) {
                let x = (fingerKnuckle.x / videoWidth) * 2 - 1;
                let y = -((fingerKnuckle.y / videoHeight) * 2 - 1); 

                ring.position.set(x * camera.aspect * 1.5, y * 1.5, 0); 
                ring.rotation.y += 0.01;
            }
        }

        renderer.render(scene, camera);
        requestAnimationFrame(detectHands);
    }

    startButton.addEventListener('click', start);
</script>
</body>
</html>
